---
title: "Defining Research Problems and Hypotheses"
module_number: 2
author: "Vivek H. Patil, Ph.D."
institution: "Gonzaga University"
subtitle: "Translating management problems into actionable research objectives, testable hypotheses, and well-structured research requests."
learning_objectives:
  - "Identify the sources of business research problems and opportunities"
  - "Translate a management problem into a precise research question with clear objectives"
  - "Develop decision statements and corresponding research objectives"
  - "Formulate testable null and alternative hypotheses"
  - "Construct a comprehensive research request using the six-part framework"
  - "Articulate the key questions that arise at each stage of the research process"
discussion_questions:
  - "Find a recent business news article that describes a company facing a strategic challenge (e.g., declining market share, customer complaints, new competitive threats). Formulate a decision statement, two research objectives, and one testable hypothesis that could guide research to address this challenge. Share your reasoning."
  - "Why is problem formulation often considered the most critical step in the research process? What are the consequences of poorly defined research problems? Provide a real or hypothetical example."
  - "The research request framework includes 'Use'—how each piece of information will be used to make a decision. Why is this step important? What happens when researchers collect information without a clear plan for how it will be used?"
  - "Consider a nonprofit organization seeking to increase donor retention. Develop a decision statement, research objective, and hypothesis. How might the Jesuit principle of *magis* (pursuing excellence for the greater good) shape how you approach this problem?"
---

## 2.1 The Central Importance of Problem Formulation

Of all the steps in the research process, **problem formulation** may be the most consequential. A brilliantly designed study that addresses the wrong question wastes time and resources. Conversely, a clear and well-defined problem sets the stage for effective research at every subsequent stage.

As the statistician John Tukey reportedly said:

> "An approximate answer to the right question is worth a great deal more than a precise answer to the wrong question."

Problem formulation is the process of **defining and developing a decision statement** and translating it into precise research terminology, including a set of research objectives and testable hypotheses (Zikmund et al., 2013). This module walks through that process step by step.

The stakes of getting problem formulation right cannot be overstated. Every subsequent decision in the research process---the choice of design, the selection of data collection methods, the construction of instruments, the sampling plan, and the analytical approach---flows from the way the problem is defined. A problem that is defined too broadly will produce research that is unfocused and difficult to act upon. A problem that is defined too narrowly may miss the true source of the issue entirely. And a problem that is fundamentally misconceived will channel resources into an investigation that, no matter how technically proficient, cannot yield useful answers. The time invested in careful, thoughtful problem formulation is therefore among the highest-return investments in the entire research process.

## 2.2 Sources of Research Problems

Research problems and opportunities arise from three primary sources, each of which reflects a different relationship between the organization and its environment. Understanding these sources helps researchers and managers recognize when formal research is needed and what kind of investigation is likely to be most productive.

### Unanticipated Change

External events that management did not foresee are among the most common triggers for business research. Economic shifts---a sudden recession, an unexpected surge in inflation, or a dramatic change in exchange rates---can upend assumptions about customer demand, pricing strategies, and supply chain costs. New regulations, whether in the form of data privacy laws, environmental standards, or trade policies, can create compliance challenges and strategic uncertainties that require investigation. Competitive moves, such as a rival's entry into a new market segment or the launch of a disruptive product, demand a response that is informed by evidence rather than reactive panic. Technological disruptions, social trends, and demographic shifts can all create problems or opportunities that the organization did not anticipate. Consider, for example, how the rapid adoption of remote work during and after the COVID-19 pandemic forced companies across industries to rethink their real estate strategies, employee engagement programs, and technology investments. In each of these cases, the unanticipated change created an information gap---a set of questions that management could not answer with existing knowledge---and it was that information gap that gave rise to the need for formal research. The distinguishing characteristic of research prompted by unanticipated change is that it is reactive: something has happened, and the organization needs to understand what it means and how to respond.

### Planned Change

Not all research is reactive. Organizations that practice proactive management regularly commission research in advance of strategic initiatives, using evidence to inform decisions before they are made rather than scrambling to understand the consequences after the fact. Before launching a new product, a well-managed company will conduct concept testing to gauge customer interest, competitive analysis to understand the landscape, and financial modeling informed by market size estimates. Before entering a new geographic market, an organization will research the regulatory environment, cultural preferences, distribution infrastructure, and competitive dynamics. Before restructuring a division, management may study employee attitudes, workflow patterns, and the experiences of comparable organizations that have undergone similar transformations. The research here is anticipatory rather than reactive---it is driven by the organization's strategic agenda rather than by an external shock. Planned change research tends to be more systematic and better resourced than research triggered by unanticipated events, because the organization has the luxury of time and can design the research to address its specific decision needs. However, it also requires a culture of evidence-based decision-making in which managers genuinely value research input and are willing to delay action until the evidence is in.

### Serendipity

Occasionally, research needs arise not from external events or strategic plans but from unexpected discoveries that catch someone's attention and spark curiosity. A sales team notices an unusual pattern in customer purchasing behavior---perhaps a product that was designed for commercial use is being purchased in surprising quantities by individual consumers. An analyst reviewing routine performance data stumbles upon an intriguing trend that does not fit any established narrative. A casual conversation with a customer at a trade show reveals an unmet need that no one in the organization had previously considered. A quality control report surfaces an anomaly that suggests a deeper issue in the production process. These serendipitous observations can be the seeds of highly valuable research investigations, but only if the organization has a culture that encourages curiosity and a process for escalating informal observations into formal research inquiries. Many important business insights have their origins not in grand strategic initiatives but in small, unexpected moments of discovery. The key is having people in the organization who are attuned to anomalies, who ask "why?" when something does not fit the expected pattern, and who have a mechanism for translating those questions into structured investigations. Organizations that dismiss or ignore serendipitous observations---because they do not fit the current strategic priorities or because "that is not what we are studying right now"---risk missing some of the most valuable learning opportunities available to them.

<div class="callout callout-case-study">
<p class="callout-title">Case Study: The Surgical Mask Manufacturer</p>
<p>Consider a manufacturer of surgical masks that has experienced a loss of sales and market share. The managerial objective is straightforward: increase company sales and profits. But the research objective is initially unclear—<em>why</em> is the company losing sales?</p>
<p>This case, adapted from Churchill and Iacobucci (2015), illustrates how problem formulation unfolds across multiple stages of research:</p>
<ul>
<li><strong>Exploratory research</strong> (Stage 1) reveals several potential causes: poor fit, excessive cost, skin irritation, and fogging of glasses.</li>
<li><strong>Descriptive research</strong> (Stage 2) prioritizes these causes: poor fit (45%), cost (12%), fogging (6%), irritation (1%).</li>
<li><strong>Causal research</strong> (Stage 3) tests whether a new dual-material molded mask (addressing the fit issue) increases sales in a field experiment with three dealers over three months.</li>
</ul>
<p>Notice how each stage depends on the previous one. Without the exploratory stage to identify possible causes, the company might have invested in the wrong solution (e.g., reducing price when the real problem was fit).</p>
</div>

## 2.3 The Problem Formulation Process

The process of formulating a research problem follows a logical sequence (adapted from Zikmund et al., 2013):

1. **Detect symptoms** — Recognize that something requires investigation (declining sales, rising complaints, a new opportunity)
2. **Analyze the situation** — Gather background information to understand the context
3. **Identify key problems** — Move beyond symptoms to underlying issues
4. **Define the problem precisely** — State what needs to be investigated in clear terms
5. **Conduct exploratory research** (optional) — If the problem is poorly understood, preliminary investigation can sharpen the definition
6. **State the decision statement** — Express the core question the decision-maker needs answered
7. **State the research objectives** — Translate the decision statement into specific, measurable information needs
8. **Develop hypotheses** — Formulate testable propositions that the research will evaluate

### Key Definitions

Several terms are central to the problem formulation process, and using them precisely is essential for clear communication between researchers and decision-makers.

**Problem definition** is the overarching process of defining and developing a decision statement and translating it into precise research terminology. It is not a single moment of insight but an iterative process that may involve multiple rounds of discussion, background research, and refinement. The goal of problem definition is to arrive at research questions that are clear, specific, and answerable through systematic investigation, and to develop well-formulated hypotheses that the study can evaluate. A common misconception is that the research problem is simply "given" by the decision-maker; in reality, the researcher plays an active role in shaping and refining the problem through dialogue, probing questions, and preliminary investigation.

A **decision statement** is a written expression of the key question or questions that the research user---typically a manager or decision-maker---wishes to answer. It articulates the decision that hangs in the balance and the uncertainty that research is intended to resolve. A good decision statement is specific enough to guide the research but broad enough to allow the researcher to investigate the problem fully. For example, "Should we introduce a premium product tier in our subscription service?" is a well-formed decision statement; "How can we make more money?" is not, because it is too vague to direct a focused investigation.

**Research objectives** are statements, in as precise terminology as possible, of what information is needed to address the decision statement. They translate the manager's question into the researcher's language, specifying the exact information that the study must produce. Research objectives should be framed so that the information obtained will directly satisfy the research purpose---that is, each objective should connect clearly to the decision at hand. If an objective cannot be linked to a specific aspect of the decision, it may be extraneous and should be reconsidered. Well-crafted research objectives are the bridge between the problem as the manager understands it and the study as the researcher designs it.

## 2.4 From Decision Statements to Research Objectives

The relationship between decision statements and research objectives is one of translation: moving from the language of management to the language of research. Consider these examples (adapted from Zikmund et al., 2013):

| Decision Statement | Research Objective(s) |
|---|---|
| Develop a package for a new product | Evaluate consumer response to alternative package designs |
| Increase store traffic | Measure the current image of the store; identify factors driving foot traffic |
| Increase market penetration by opening new stores | Evaluate prospective locations based on demographic and competitive data |
| Decide which merchandise will be available online | Determine consumers' confidence in purchasing different product categories without physical inspection |

Notice that the decision statement frames the **management problem** (what the manager wants to do), while the research objectives frame the **information needed** to make that decision. The research objective must be specific enough to guide the design of the study. A vague objective like "learn about our customers" provides no direction; a precise objective like "determine the percentage of current customers who would switch to a competitor if our price increased by 10%" tells the researcher exactly what to measure, whom to study, and what kind of data to collect.

The translation from decision statement to research objective is rarely mechanical. It requires the researcher to think carefully about what information, if obtained, would actually help the decision-maker choose a course of action. This often involves asking probing questions: What would you do differently if you knew X? What information would change your mind? What are the specific alternatives you are choosing among? These questions help ensure that the research objectives are not just intellectually interesting but practically useful.

## 2.5 Hypothesis Development

Once research objectives are established, the researcher develops **hypotheses**---specific, testable propositions about the expected relationships between variables. Hypotheses serve as the bridge between the research question and the research design.

The flow is:

**Decision Statement → Theory / Experience / Exploratory Research → Research Objective → Hypothesis → Research Design**

### Examples

| Decision Statement | Research Objective | Hypothesis |
|---|---|---|
| What should be the retail price for product X? | Forecast sales at three price points ($4.00, $5.00, $6.99) | Sales will be higher at $5.00 than at $4.00 or $6.99 |
| What should we invest in to improve service quality? | Identify top factors contributing to service quality perceptions | Cleanliness is positively related to service quality perceptions; crowding is negatively related to service quality perceptions |
| Should we invest in a training program to reduce role conflict? | Determine the influence of role conflict on employee job satisfaction | Role conflict is negatively related to job satisfaction |

A well-formulated hypothesis has several characteristics that distinguish it from mere speculation or wishful thinking. First, it is **specific**, stating a clear expected relationship between identified variables. A hypothesis that says "marketing affects sales" is too vague to be useful; a hypothesis that says "a 15% increase in digital advertising spend will increase online sales by at least 5% within 90 days" provides a clear, testable prediction. Second, it is **testable**---capable of being confirmed or disconfirmed with empirical data. A hypothesis that cannot be evaluated with available or obtainable evidence is not a research hypothesis; it is a philosophical proposition. Third, it is **grounded** in theory, prior research, or informed judgment rather than mere guesswork. Hypotheses should be derived from a logical foundation---a theoretical framework that explains why the expected relationship should exist, previous empirical findings that suggest it does, or at minimum, informed professional experience that points in a particular direction. Grounding hypotheses in existing knowledge ensures that the research builds on what is already known rather than starting from scratch.

<div class="callout callout-key-concept">
<p class="callout-title">Key Concept: Null and Alternative Hypotheses</p>
<p>In formal hypothesis testing (covered in depth in Module 8), we distinguish between:</p>
<ul>
<li><strong>Null hypothesis (H₀)</strong>: The default assumption—typically that there is no effect, no difference, or no relationship</li>
<li><strong>Alternative hypothesis (H₁ or Hₐ)</strong>: The proposition the researcher seeks evidence for—that an effect, difference, or relationship does exist</li>
</ul>
<p>For example: H₀: Average customer satisfaction does not differ between Store A and Store B. Hₐ: Average customer satisfaction differs between Store A and Store B.</p>
</div>

## 2.6 The Research Request: A Six-Part Framework

Before a research project begins, a formal **research request** helps ensure alignment between the decision-maker and the researcher. A well-structured research request includes six components (Churchill & Iacobucci, 2015). Each component serves a distinct purpose in clarifying the scope, rationale, and practical parameters of the study, and together they form a comprehensive brief that enables the researcher to design a study that genuinely serves the decision-maker's needs.

The first component is **Action**---a clear statement of what actions are being considered on the basis of the research. This forces both the decision-maker and the researcher to think concretely about how the results will be used. Too often, research is commissioned in the abstract ("We need to understand our market better") without a clear connection to specific decisions. By articulating the contemplated actions upfront---for example, "We are deciding whether to invest $2 million in drive-through construction at 15 locations"---the research request anchors the entire study in a concrete decision context. This clarity disciplines every subsequent element of the research design, ensuring that the study produces actionable output rather than interesting-but-irrelevant information.

The second component is **Origin**---the events, circumstances, or observations that led to the need for research. Understanding the origin helps the researcher appreciate the broader context in which the decision is being made, even when the origin does not directly affect the research design. If a company is considering a new product launch because a competitor has just entered the market with a similar offering, that competitive context shapes how the researcher interprets the urgency, the relevant comparison points, and the strategic implications of the findings. Origin information also helps the researcher assess whether the decision-maker's framing of the problem is complete or whether additional background investigation is warranted.

The third component is **Information**---the specific questions that the decision-maker needs answered. This is the heart of the research request, the element that most directly shapes the study design. The information requirements should be stated as precisely as possible, ideally in the form of specific questions: What percentage of current customers would use a drive-through? What is the expected increase in visit frequency? What is the estimated revenue impact per location? Vague information requirements like "tell us about customer preferences" are insufficient because they do not provide the researcher with enough direction to design a focused, efficient study.

The fourth component is **Use**---a specification of how each piece of information will be used to make the decision. This is perhaps the most underappreciated element of the research request, and also one of the most valuable. By explicitly linking each information requirement to a specific decision action, the Use component ensures that every question in the research serves a defined purpose. If a piece of information cannot be connected to a specific aspect of the decision, it may not be worth collecting. This discipline prevents scope creep, reduces costs, and ensures that the final report delivers exactly what the decision-maker needs. For instance, knowing that customer demand estimates will feed directly into a financial model for ROI calculation tells the researcher not only what to measure but also the level of precision required.

The fifth component is **Targets and Subgroups**---a specification of from whom the information must be gathered. Identifying the target population is essential for designing an appropriate sampling plan, but it also forces the decision-maker to think about whose perspectives matter for the decision at hand. Should the study include only current customers, or also potential customers in the surrounding area? Should it segment by demographics, usage frequency, or geographic location? The answers to these questions affect the generalizability and relevance of the findings. In some cases, the most valuable insights come not from the obvious target group (existing customers) but from a less obvious one (people who considered the product but chose a competitor, or people who live nearby but have never visited).

The sixth component is **Logistics**---the practical constraints of time and budget. Both constraints significantly affect the feasible research methods and scope. A study that must deliver results within three weeks cannot employ the same methods as one with a six-month timeline. A budget of $10,000 limits the researcher to secondary data analysis and perhaps a small online survey, whereas a budget of $500,000 opens up possibilities for large-scale quantitative studies, focus groups, in-depth interviews, and experimental designs. Being explicit about logistics from the outset prevents the frustration that arises when a beautifully designed study proves impractical given the available resources.

<div class="callout callout-example">
<p class="callout-title">Example: Regional Coffee Chain</p>
<p>A regional coffee chain is considering adding a drive-through service at existing locations.</p>
<ul>
<li><strong>Action</strong>: Decide whether to invest $2M in drive-through construction at 15 locations</li>
<li><strong>Origin</strong>: Competitors with drive-throughs have seen 20% revenue increases; customer feedback mentions convenience</li>
<li><strong>Information</strong>: (a) What percentage of current customers would use a drive-through? (b) What is the expected increase in visit frequency? (c) What is the estimated revenue impact per location?</li>
<li><strong>Use</strong>: (a) determines demand; (b) and (c) feed the financial model for ROI calculation</li>
<li><strong>Targets</strong>: Current customers at the 15 candidate locations; non-customers in surrounding 5-mile radius</li>
<li><strong>Logistics</strong>: Results needed within 6 weeks; budget of $75,000</li>
</ul>
</div>

## 2.7 Key Questions at Each Stage of the Research Process

One of the most practical skills in research is knowing which questions to ask at each stage of the process. The questions that are relevant during problem formulation are quite different from those that arise during data collection or analysis, and failing to ask the right questions at the right time can lead to costly oversights. The following framework, adapted from Churchill and Iacobucci (2015), provides a comprehensive guide organized by stage. Rather than treating these as isolated checklists, it is useful to think of them as a progressive narrowing of focus---from the broad strategic questions of problem formulation to the precise technical questions of analysis and reporting.

### Problem Formulation Stage

The problem formulation stage is where the broadest and most consequential questions are asked. At this point, the researcher and the decision-maker must establish the fundamental purpose of the investigation and determine whether research is warranted at all. The central question is deceptively simple: What is the purpose of the study? Is it to solve an existing problem, to identify a new opportunity, or to evaluate a proposed course of action? Closely related is the question of whether additional background information is needed before the problem can be defined precisely. In many cases, a review of secondary data, conversations with knowledgeable insiders, or a brief exploratory investigation is necessary to sharpen the problem definition. The researcher must also determine what specific information is needed to make the decision, how that information will be utilized once obtained, and---critically---whether formal research should be conducted at all. Sometimes the expected value of the information does not justify the cost, or the decision must be made so quickly that a formal study is impractical. Recognizing when not to conduct research is itself an important research skill.

### Research Design Stage

Once the problem is clearly defined, the focus shifts to designing a study that can address it effectively. The key questions at this stage concern the current state of knowledge: How much is already known about this problem? If the territory is largely uncharted, an exploratory design may be appropriate; if substantial prior knowledge exists, a more structured descriptive or causal design may be warranted. The researcher must assess whether a testable hypothesis can be formulated or whether the study is more appropriately framed as an open-ended exploration. The types of questions that need to be answered---descriptive questions about the current state of affairs, comparative questions about differences between groups, or causal questions about the effects of specific interventions---will determine the type of study that best addresses the research objectives.

### Data Collection Method and Forms Stage

With the design established, the researcher must make a series of practical decisions about how data will actually be gathered. This stage involves questions about whether existing data can answer the research questions or whether new data must be collected. If new data are required, the researcher must determine what is to be measured and how, identify the source of the data (customers, employees, archival records, observational settings), and decide whether objective answers can be obtained by asking people or whether observation or behavioral data are necessary. If people are to be questioned, further decisions arise about the mode of data collection---in person, by telephone, online, or by mail---each of which carries different implications for response rates, data quality, cost, and timeline. The researcher must also decide whether to use structured instruments (with fixed questions and response options) or unstructured approaches (open-ended questions that allow respondents to answer in their own words), whether the study purpose should be disclosed to respondents or whether some degree of concealment is necessary to avoid biasing the results, and whether rating scales should be employed. Each of these decisions involves trade-offs that must be weighed in light of the specific research objectives and practical constraints.

### Sampling and Data Collection Stage

The sampling and data collection stage requires the researcher to specify exactly who will be studied and how the data collection will be managed. Defining the target population is the starting point: Who are the people (or organizations, or transactions, or events) about which the research seeks to draw conclusions? From there, the researcher must determine whether a list of population elements is available to serve as a sampling frame, whether a sample is appropriate or whether a census of the entire population is feasible and desirable, and whether a probability sampling method (which allows for statistical generalization) or a nonprobability method (which may be faster and cheaper but limits generalizability) should be used. Sample size is another critical decision, influenced by the desired level of precision, the expected variability in the population, and the available budget. Finally, operational questions about who will collect the data, what supervisory and quality control procedures will be in place, and how fieldwork logistics will be managed must be addressed before data collection begins.

### Analysis and Interpretation Stage

Once data are collected, the researcher faces questions about how to transform raw data into meaningful findings. The data must be edited and coded---checked for errors, inconsistencies, and completeness, and then transformed into a format suitable for analysis. The researcher must determine which tabulations, visualizations, and statistical techniques are appropriate given the research questions, the type of data collected, and the assumptions underlying different analytical methods. The choice of analysis techniques should follow from the research design and objectives, not the other way around; selecting a statistical method and then looking for a question it can answer is a recipe for misleading results.

### Reporting Stage

The final set of questions concerns how the findings will be communicated. The researcher must consider who will read the report and what their level of technical sophistication is---a report for a chief marketing officer will differ substantially in tone, detail, and emphasis from a report for a team of data scientists. The researcher must determine whether managerial recommendations are expected (in most applied research, they are) and what format the written and oral reports should take. Effective reporting is not an afterthought; it is the mechanism by which research findings are translated into organizational action, and a study that is poorly communicated is a study that fails to achieve its purpose.

## 2.8 Research Boundaries and Scope

An often-overlooked aspect of problem formulation is defining what the research will **not** cover. Every research project operates within boundaries, and articulating those boundaries clearly is essential for managing expectations, focusing resources, and preventing the kind of scope creep that can derail even well-designed studies.

**Geographic scope** defines the spatial boundaries of the study. The researcher must determine whether the investigation covers a single market (a city, a state, a country) or spans multiple regions. A study of customer satisfaction at a regional restaurant chain, for example, might focus on a specific metropolitan area, or it might encompass all locations across several states. The choice has significant implications for sampling strategy, data collection logistics, and the generalizability of the findings. A study conducted in one city may not be generalizable to other markets with different demographics, competitive landscapes, or cultural norms.

**Time frame** specifies whether the research is concerned with current conditions, historical trends, or future projections. A study of current customer attitudes captures a snapshot in time, while a longitudinal study tracks changes over weeks, months, or years. The time frame affects not only the research design but also the relevance and shelf life of the findings. A rapidly evolving market may render even recent findings obsolete within months.

**Population boundaries** determine which stakeholders are included in the study. Should the research focus exclusively on current customers, or should it also include former customers, potential customers, employees, suppliers, or community members? Each population brings different perspectives and different information, and the decision about whom to include should be driven by the research objectives and the decision context. Studying only current customers, for example, may provide a biased picture if the most important insights reside with people who have already defected to a competitor.

**Depth versus breadth** represents a fundamental trade-off in research design. A study that examines a few variables in great depth (such as an in-depth qualitative study of customer decision-making processes) yields rich, nuanced understanding but may not be generalizable to the broader population. A study that surveys many variables across a large sample (such as a national customer satisfaction survey) provides breadth and generalizability but may miss the subtleties and contextual factors that drive behavior. The decision about where to position a study on the depth-breadth spectrum depends on the research objectives, the current state of knowledge, and the resources available.

Setting clear boundaries prevents scope creep---the tendency for research projects to expand beyond their original mandate, consuming time and budget without proportional gains in useful information. Scope creep often begins innocuously, with a stakeholder suggesting "while we are at it, we should also ask about..." or "it would be interesting to know whether..." These additions may individually seem reasonable, but collectively they can transform a focused, manageable study into an unwieldy project that takes too long, costs too much, and produces a report so sprawling that the key findings are buried. The discipline of defining boundaries upfront and adhering to them throughout the project is one of the hallmarks of effective research management.

<div class="callout callout-jesuit">
<p class="callout-title">Jesuit Perspective</p>
<p>Problem formulation is inherently an act of framing: what we choose to study—and what we choose not to study—reflects our values and priorities. The Jesuit tradition encourages us to ask not only "What is the most profitable question?" but also "What is the most important question?" Sometimes the most impactful research addresses the needs of underserved stakeholders, marginalized communities, or overlooked dimensions of a problem. <em>Magis</em>—the pursuit of the greater good—challenges us to formulate problems that matter.</p>
</div>

## 2.9 Common Pitfalls in Problem Formulation

Even experienced researchers can fall into traps during problem formulation, and awareness of these common pitfalls is the first line of defense against them.

Perhaps the most pervasive pitfall is **confusing symptoms with problems**. Declining sales, rising customer complaints, or increasing employee turnover are not problems in themselves---they are symptoms of underlying problems that the research must identify. Declining sales might be caused by deteriorating product quality, a shift in customer preferences, aggressive competitor pricing, inadequate distribution, an ineffective advertising campaign, or any number of other factors. A research study that takes "declining sales" as its problem and attempts to investigate "how to increase sales" without first diagnosing the underlying cause is likely to produce recommendations that address the wrong issue. Effective problem formulation requires the discipline to look beneath the surface symptoms and identify the root causes that the research should investigate.

A closely related pitfall is **defining the problem too broadly**. Statements like "We need to understand our customers better" or "We want to improve our competitive position" are not research problems; they are strategic aspirations. A research problem must be specific enough to guide the design of a focused study. When a problem is defined too broadly, the resulting research tends to be unfocused---trying to answer too many questions at once, collecting data on too many variables, and ultimately producing a report that is comprehensive in scope but shallow in insight. Narrowing the problem to a specific, actionable question ("What factors are driving customer attrition among subscribers who joined in the past 12 months?") gives the research a clear target and makes it far more likely to produce useful results.

Conversely, **defining the problem too narrowly** can be equally damaging. If the researcher accepts an overly restricted framing of the problem, the study may miss the real issue entirely. Consider a company that asks its research team to study whether its prices are too high, when the actual problem is that a new competitor is offering a superior product at a comparable price. A study focused exclusively on price sensitivity will not uncover the product quality gap, and the company may respond by cutting prices---a costly strategy that does not address the fundamental competitive challenge. The researcher's role is to question the initial framing, explore the broader context, and ensure that the problem definition is neither so narrow that it excludes the real issue nor so broad that it becomes unmanageable.

Finally, there is the pitfall of **accepting the client's initial framing uncritically**. Decision-makers who commission research often come to the researcher with a preconceived notion of what the problem is and, sometimes, a preferred answer. The client may say, "We need to know whether our advertising is effective," when the real issue is that the product does not meet customer expectations and no amount of advertising will fix it. The researcher's job is not simply to execute the client's initial request but to probe, question, challenge assumptions, and refine the problem definition through dialogue and preliminary investigation. This consultative role requires both technical skill and interpersonal diplomacy---the ability to redirect the investigation toward the right question without alienating the decision-maker. Researchers who simply accept the first formulation they are given risk conducting studies that are technically competent but strategically irrelevant.

---

## Recommended Resources

### Academic Texts
- Zikmund, W. G., Babin, B. J., Carr, J. C., & Griffin, M. (2013). *Business Research Methods* (9th ed.). Cengage Learning. — Chapters 5–6.
- Churchill, G. A., & Iacobucci, D. (2015). *Marketing Research: Methodological Foundations*. Cengage Learning. — Chapters 5–6.
- Kumar, V., Aaker, D. A., & Day, G. S. (2002). *Essentials of Marketing Research*. Wiley. — Chapters 2–3.

### Articles
- Andreasen, A. R. (1985). "'Backward' Market Research." *Harvard Business Review*, 63(3), 176–182. — A classic argument for starting with the decision, not the data.

### Companion Resource
- Patil, V. H. (2024). *Notes on Survey Design*, Chapter 2: Survey Process and Errors — [patilv.com/Survey-Design/chapters/chapter-2/](https://patilv.com/Survey-Design/chapters/chapter-2/)
